<!DOCTYPE html>
<html lang="zh-CN">
<head><meta name="generator" content="Hexo 3.9.0">
    <meta charset="UTF-8">

    

    

    <title>我喜欢你喜欢我的歌</title>
    <meta name="author" content="Dick Zhong">
    <meta name="version" content="1.0.0">
    <meta name="keywords" content>
    <meta name="description" content>
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    <meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no">

    
    <link rel="alternate" href="/atom.xml" title="我喜欢你喜欢我的歌" type="application/atom+xml">
    
    
    <link rel="icon" href="/images/favicon.ico">
    

    <link rel="stylesheet" href="/css/style.css">
</head>
<body>

    <main class="app">
        <header class="header clearfix">
    <div id="nav" class="nav">
    <div class="nav-mobile">
        <button id="open-panel" class="open-panel nav-mobile-item"><i class="icon-documents"></i></button>
        <h1 class="nav-mobile-title nav-mobile-item">我喜欢你喜欢我的歌</h1>
        <button id="open-menus" class="open-panel nav-mobile-item"><i class="icon-library"></i></button>
    </div>

    <nav id="nav-inner" class="nav-inner">
        
            <a class="nav-item active" href="/">
                <span class="nav-text">首页</span>
            </a>
        
            <a class="nav-item" href="/categories/">
                <span class="nav-text">分类</span>
            </a>
        
            <a class="nav-item" href="/tags">
                <span class="nav-text">标签</span>
            </a>
        
            <a class="nav-item" href="/archives">
                <span class="nav-text">归档</span>
            </a>
        
            <a class="nav-item" href="/atom.xml">
                <span class="nav-text">订阅</span>
            </a>
        
            <a class="nav-item" href="/about">
                <span class="nav-text">关于</span>
            </a>
        
    </nav>
</div>

    <aside id="aside" class="aside">
    <div id="aside-mask" class="aside-mask"></div>
    <div id="aside-inner" class="aside-inner">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit"><i class="icon-search-stroke"></i></button><input type="hidden" name="sitesearch" value="https://wxzhongwang.github.io"></form>

        
        

        
        <div class="author-meta">
            
            <div class="author-avatar">
                <a href="/">
                    <img src="/images/27359059.jpg" title="咸鱼有点咸">
                </a>
            </div>
            
            <div class="author-name">咸鱼有点咸</div>
            <div class="author-work">Developer</div>
            <div class="author-location">
                <i class="icon-location vm"></i>
                <span class="vm">Hangzhou, China</span>
            </div>
            
            <div class="author-thread-wrap">
                <div class="author-threads clearfix">
                    
                        <a class="thread-item" href="https://github.com/wxzhongwang" target="_blank" rel="noopener">
                            <!-- Generated by IcoMoon.io -->
<svg viewbox="0 0 1024 1024" width="38" height="38" fill="currentColor">
<path d="M512 32.12c-265.004 0-479.88 220.23-479.88 492.090 0 217.446 137.536 401.684 328.202 466.81 23.994 4.498 32.778-10.712 32.778-23.78 0-11.782-0.428-42.632-0.642-83.764-133.466 29.778-161.744-65.984-161.744-65.984-21.852-56.772-53.344-71.982-53.344-71.982-43.49-30.636 3.214-29.992 3.214-29.992 48.202 3.428 73.482 50.772 73.482 50.772 42.846 75.196 112.258 53.558 139.68 40.918 4.284-31.706 16.71-53.558 30.42-65.77-106.474-12.426-218.516-54.63-218.516-243.152 0-53.772 18.638-97.69 49.274-131.966-4.928-12.426-21.424-62.556 4.714-130.252 0 0 40.276-13.282 131.966 50.344 38.348-10.926 79.266-16.282 120.184-16.496 40.704 0.214 81.836 5.57 120.184 16.496 91.692-63.626 131.752-50.344 131.752-50.344 26.136 67.698 9.64 117.828 4.714 130.252 30.636 34.492 49.274 78.408 49.274 131.966 0 188.952-112.258 230.514-219.16 242.724 17.138 15.21 32.564 45.202 32.564 91.048 0 65.77-0.642 118.898-0.642 134.966 0 13.068 8.57 28.492 32.992 23.566 191.094-64.912 328.418-249.152 328.418-466.382 0-271.86-214.874-492.090-479.88-492.090z"/>
</svg>

                        </a>
                    
                        <a class="thread-item" href="https://weibo.com/u/6558527999" target="_blank" rel="noopener">
                            <!-- Generated by IcoMoon.io -->
<svg viewbox="0 0 1024 1024" width="38" height="38" fill="currentColor">
<path d="M21.332 512c0-270.988 219.68-490.666 490.668-490.666s490.666 219.68 490.666 490.666c0 270.988-219.678 490.666-490.666 490.666s-490.666-219.678-490.666-490.666zM960 512c0-247.424-200.576-448-448-448s-448 200.576-448 448c0 247.424 200.576 448 448 448s448-200.576 448-448zM768 597.332c47.128 0 85.332-38.206 85.332-85.332s-38.206-85.332-85.332-85.332c-47.128 0-85.332 38.204-85.332 85.332s38.206 85.332 85.332 85.332zM512 597.332c47.128 0 85.332-38.206 85.332-85.332s-38.206-85.332-85.332-85.332c-47.128 0-85.332 38.204-85.332 85.332s38.204 85.332 85.332 85.332zM255.998 597.332c47.128 0 85.332-38.206 85.332-85.332s-38.204-85.332-85.332-85.332c-47.128 0-85.332 38.204-85.332 85.332s38.204 85.332 85.332 85.332z"/>
</svg>

                        </a>
                    
                        <a class="thread-item" href="https://twitter.com/wxzhongwang" target="_blank" rel="noopener">
                            <!-- Generated by IcoMoon.io -->
<svg viewbox="0 0 1024 1024" width="38" height="38" fill="currentColor">
<path d="M512.029 31.011c-263.32 0-476.784 213.502-476.784 476.784 0 263.32 213.464 476.743 476.784 476.743s476.743-213.424 476.743-476.743c0-263.282-213.444-476.784-476.743-476.784zM752.193 411.663c0.251 5.151 0.349 10.319 0.349 15.548 0 158.786-120.856 341.85-341.85 341.85-67.844 0-131.021-19.884-184.188-53.961 9.41 1.104 18.955 1.665 28.656 1.665 56.305 0 108.115-19.208 149.221-51.425-52.567-0.987-96.925-35.741-112.22-83.468 7.32 1.433 14.85 2.149 22.595 2.149 10.959 0 21.569-1.433 31.656-4.201-54.987-11.035-96.402-59.634-96.402-117.796 0-0.524 0-1.025 0.020-1.549 16.186 9.003 34.716 14.404 54.427 15.044-32.258-21.587-53.458-58.317-53.458-100.023 0-22.015 5.925-42.673 16.264-60.408 59.266 72.683 147.807 120.527 247.676 125.521-2.053-8.77-3.118-17.968-3.118-27.378 0-66.333 53.787-120.14 120.158-120.14 34.561 0 65.771 14.599 87.69 37.93 27.378-5.363 53.091-15.393 76.305-29.16-9.003 28.074-28.036 51.618-52.858 66.47 24.338-2.903 47.495-9.37 69.024-18.917-16.070 24.144-36.459 45.306-59.945 62.248z"/>
</svg>

                        </a>
                    
                </div>
            </div>
            
        </div>
        
    </div>
</aside>

</header>

        <div id="content" class="content">
    <article class="article" itemscope itemprop="blogPost">
    
    <header class="article-header">
        
        <h1 itemprop="name">
            <a href="/2019/02/04/Greenplum 从入门到放弃（四）/">Greenplum 从入门到放弃 四</a>
        </h1>
        
        <div class="article-meta clearfix">
            <a class="article-date" href="https://wxzhongwang.github.io/page/4/index.html">
    
    <i class="icon-calendar"></i>
    
    <time datetime="2019-02-04T02:10:00.000Z" itemprop="datePublished">2019-02-04</time>
</a>

            
<div class="article-tag-list">
    <i class="icon-tag"></i>
    <a class="article-tag-link" href="/tags/Greenplum/">Greenplum</a>
</div>


        </div>
    </header>
    
    <section class="article-body markdown-body">
        
        <h1 id="Greenplum-从入门到放弃（四）"><a href="#Greenplum-从入门到放弃（四）" class="headerlink" title="Greenplum 从入门到放弃（四）"></a>Greenplum 从入门到放弃（四）</h1><h2 id="PostgreSQL与Greenplum的关系"><a href="#PostgreSQL与Greenplum的关系" class="headerlink" title="PostgreSQL与Greenplum的关系"></a>PostgreSQL与Greenplum的关系</h2><h3 id="PostgreSQL"><a href="#PostgreSQL" class="headerlink" title="PostgreSQL"></a>PostgreSQL</h3><p>PostgreSQL是一种非常先进的对象–关系型数据库管理系统（ORDBMS），是目前功能最强大，特性最丰富和技术最先进的自由软件数据库系统之一，其某些特性甚至连商业数据库都不具备。</p>
<p>PostgreSQL的特点可以说是数不胜数，称其为最先进的开<br>源软件数据库当之无愧，支持绝大部分的主流数据库特性，主<br>要体现在如下几方面：</p>
<ol>
<li>函数/存储过程</li>
</ol>
<p>PostgreSQL对非常丰富的过程类语言提供支持，可以编写自定义函数/存储过程</p>
<ul>
<li>内置的plpgsql，一种类似Oracle的PLsql的语言</li>
<li>支持的脚本语言有：PL/Lua、PL/LOLCODE、PL/Perl、PL/HP、PL/Python、PL/Ruby、PL/sh、PL/Tcl和PL/Scheme。、</li>
<li>编译语言有C、C++和JAVA。</li>
<li>·统计语言PL/R</li>
</ul>
<ol start="2">
<li>索引</li>
</ol>
<p>PostgreSQL支持用户定义的索引访问方法，并且内置了Btree、哈希和GiST索引。PostgreSQL中的索引有下面几个特点：</p>
<ul>
<li>可以从后向前扫描</li>
<li>可以创建表达式索引</li>
<li>部分索引</li>
</ul>
<ol start="3">
<li>触发器</li>
</ol>
<p>触发器是由SQL查询的动作触发的事件。比如，一个INSERT查询可能激活一个检查输入值是否有效的触发器。大多数触发器都只对INSERT或者UPDATE查询有效。PostgreSQL完全支持触发器，可以附着在表上，但是不能在视图上。不过视图可以有规则。多个触发器是按照字母顺序触发的。我们还可以用其他过程语言书写触发器函数，不仅仅PL/PgSQL。</p>
<ol start="4">
<li>并发管理（MVCC）</li>
</ol>
<p>PostgreSQL的并发管理使用的是一种叫做“MVCC”（多版本并发机制）的机制，这种机制实际上就是现在在众多所谓的编程语言中极其火爆的“Lock Free”，其本质是通过类似科幻世界的时空穿梭的原理，给予每个用户一个自己的“时空”<br>，然后通过原子的“时空”控制来控制时间基线，并以此控制并发更改的可见区域，从而实现近乎无锁的并发，而同时还能在很大程度上保证数据库的ACID特性。</p>
<ol start="5">
<li>规则（RULE）</li>
</ol>
<p>规则允许我们对由一个查询生成的查询树进行改写。</p>
<ol start="6">
<li>数据类型</li>
</ol>
<p>PostgreSQL支持非常广泛的数据类型，包括：</p>
<ul>
<li>任意精度的数值类型；</li>
<li>无限长度的文本类型；</li>
<li>几何原语；</li>
<li>IPv4和IPv6类型；</li>
<li>CIDR块和MAC地址；</li>
<li>数组。</li>
</ul>
<p>用户还可以创建自己的类型，并且可以利用GiST框架把这些类型做成完全可索引的，比如来自PostGIS的地理信息系统（GIS）的数据类型。</p>
<ol start="7">
<li>用户定义对象</li>
</ol>
<p>因为PostgreSQL使用一种基于系统表的可扩展的结构设计，所以PostgreSQL内部的几乎所有对象都可以由用户定义，这些对象包括：</p>
<ul>
<li>索引；</li>
<li>操作符（内部操作符可以被覆盖）；</li>
<li>聚集函数；</li>
<li>域；</li>
<li>类型转换；</li>
<li>编码转换。</li>
</ul>
<ol start="8">
<li>继承</li>
</ol>
<p>PostgreSQL的表是可以相互继承的。一个表可以有父表，<br>父表的结构变化会导致子表的结构变化，而对子表的插入和数<br>据更新等也会反映到父表中。</p>
<ol start="9">
<li>其他特性与扩展</li>
</ol>
<ul>
<li>二进制和文本大对象存储；</li>
<li>在线备份；</li>
<li>TOAST（The Oversized-Attribute Storage Technique）用于透明地在独立的地方保存大的数据库属性，当数据超过一定大小的时候，会自动进行压缩以节省空间；</li>
<li>正则表达式。</li>
</ul>
<p>此外PostgreSQL还有大量的附加模块和扩展版本，比如，多种不同的主从/主主复制方案:</p>
<ul>
<li>Slony-I；</li>
<li>pgcluster；</li>
<li>Mammoth replicator；</li>
<li>Bucardo。</li>
</ul>

        
    </section>
</article>


    <article class="article" itemscope itemprop="blogPost">
    
    <header class="article-header">
        
        <h1 itemprop="name">
            <a href="/2019/02/03/Greenplum 从入门到放弃（三）/">Greenplum 从入门到放弃 三</a>
        </h1>
        
        <div class="article-meta clearfix">
            <a class="article-date" href="https://wxzhongwang.github.io/page/4/index.html">
    
    <i class="icon-calendar"></i>
    
    <time datetime="2019-02-03T02:10:00.000Z" itemprop="datePublished">2019-02-03</time>
</a>

            
<div class="article-tag-list">
    <i class="icon-tag"></i>
    <a class="article-tag-link" href="/tags/Greenplum/">Greenplum</a>
</div>


        </div>
    </header>
    
    <section class="article-body markdown-body">
        
        <h1 id="Greenplum-从入门到放弃（三）"><a href="#Greenplum-从入门到放弃（三）" class="headerlink" title="Greenplum 从入门到放弃（三）"></a>Greenplum 从入门到放弃（三）</h1><h2 id="master-和-segment关系"><a href="#master-和-segment关系" class="headerlink" title="master 和 segment关系"></a>master 和 segment关系</h2><p>Master和Segment其实都是一个单独的PostgreSQL数据库。<br>每一个都有自己单独的一套元数据字典，在这里，Master节点<br>一般也叫主节点，Segment也叫做数据节点。<br>Segment节点与Master节点的通信，通过千兆（或万兆）<br>网卡组成的内部连接（InterConnect），在同一台数据节点机<br>器上可以放多个Segment，不同的Segment节点会被赋予不同的<br>端口，同时，Segment之间也不断地进行着交互。为了实现高<br>可用，每个Segment都有对应的备节点（Mirror Segment），分<br>别存在于不同的机器上。</p>
<blockquote>
<p>Client一般只能与Master节点进行交互，Client将SQL发给Master，然后Master对SQL进行分析后，再将其分配给所有的Segment进行操作，并且将汇总结果返回给客户端。</p>
</blockquote>
<h2 id="数据库存储"><a href="#数据库存储" class="headerlink" title="数据库存储"></a>数据库存储</h2><p>对于数据库来说，在性能上磁盘IO很容易成为瓶颈，由于数据库的特性，每一个SQL基本都是对全表数据进行分析，每次处理的数据量非常大，数据基本上都是没有缓存的（数据字典除外），极度消耗IO资源（全表扫描主要都是顺序IO），所以Greenplum对存储的要求比较高。在文件系统的选择上，在Linux下建议使用XFS，在Solaris下建议使用ZFS，对于Raid根据需求选择硬Raid或软Raid，如果需要更大的空间，建议使用Raid5，如果对性能有更高的要求，可以选择Raid 1+0。</p>
<h2 id="网络"><a href="#网络" class="headerlink" title="网络"></a>网络</h2><p>在确定机器配置的时候，要保证所有机器的网络都是通的，并且每台机器的防火墙都是关闭的，避免存在网络不通的问题。</p>

        
    </section>
</article>


    <article class="article" itemscope itemprop="blogPost">
    
    <header class="article-header">
        
        <h1 itemprop="name">
            <a href="/2019/02/02/Greenplum 从入门到放弃（二）/">Greenplum 从入门到放弃 二</a>
        </h1>
        
        <div class="article-meta clearfix">
            <a class="article-date" href="https://wxzhongwang.github.io/page/4/index.html">
    
    <i class="icon-calendar"></i>
    
    <time datetime="2019-02-02T02:10:00.000Z" itemprop="datePublished">2019-02-02</time>
</a>

            
<div class="article-tag-list">
    <i class="icon-tag"></i>
    <a class="article-tag-link" href="/tags/Greenplum/">Greenplum</a>
</div>


        </div>
    </header>
    
    <section class="article-body markdown-body">
        
        <h1 id="Greenplum-从入门到放弃（二）"><a href="#Greenplum-从入门到放弃（二）" class="headerlink" title="Greenplum 从入门到放弃（二）"></a>Greenplum 从入门到放弃（二）</h1><h2 id="OLTP与OLAP"><a href="#OLTP与OLAP" class="headerlink" title="OLTP与OLAP"></a>OLTP与OLAP</h2><p>数据库系统一般分为两种类型，一种是面向前台应用的，应用比较简单，但是重吞吐和高并发的OLTP类型；一种是重计算的，对大数据集进行统计分析的OLAP类型。Greenplum属于后者。</p>
<p>OLTP（On-Line Transaction<br>Processing，联机事务处理）系统也称为生产系统，它是事件驱动的、面向应用的，比如电<br>子商务网站的交易系统就是一个典型的OLTP系统。OLTP的基本特点是：</p>
<ul>
<li>数据在系统中产生</li>
<li>基于交易的处理系统（Transaction-Based）</li>
<li>每次交易牵涉的数据量很小</li>
<li>对响应时间要求非常高</li>
<li>用户数量非常庞大，主要是操作人员</li>
<li>数据库的各种操作主要基于索引进行</li>
</ul>
<p>OLAP（On-Line Analytical Processing，联机分析处理）是基于数据仓库的信息分析处理过程，是数据仓库的用户接口部分。OLAP系统是跨部门的、面向主题的，其基本特点是：</p>
<ul>
<li>本身不产生数据，其基础数据来源于生产系统中的操作数据（OperationalData）</li>
<li>基于查询的分析系统</li>
<li>复杂查询经常使用多表联结、全表扫描等，牵涉的数据量往往十分庞大</li>
<li>响应时间与具体查询有很大关系</li>
<li>用户数量相对较小，其用户主要是业务人员与管理人员</li>
<li>由于业务问题不固定，数据库的各种操作不能完全基于索引进行</li>
</ul>

        
    </section>
</article>


    <article class="article" itemscope itemprop="blogPost">
    
    <header class="article-header">
        
        <h1 itemprop="name">
            <a href="/2019/02/01/Greenplum 从入门到放弃（一）/">Greenplum 从入门到放弃 一</a>
        </h1>
        
        <div class="article-meta clearfix">
            <a class="article-date" href="https://wxzhongwang.github.io/page/4/index.html">
    
    <i class="icon-calendar"></i>
    
    <time datetime="2019-02-01T02:10:00.000Z" itemprop="datePublished">2019-02-01</time>
</a>

            
<div class="article-tag-list">
    <i class="icon-tag"></i>
    <a class="article-tag-link" href="/tags/Greenplum/">Greenplum</a>
</div>


        </div>
    </header>
    
    <section class="article-body markdown-body">
        
        <h1 id="Greenplum-从入门到放弃（一）"><a href="#Greenplum-从入门到放弃（一）" class="headerlink" title="Greenplum 从入门到放弃（一）"></a>Greenplum 从入门到放弃（一）</h1><ul>
<li><p>Greenplum的性能在数据量为TB级别时表现非常优秀，单机性能相比Hadoop要快好几倍</p>
</li>
<li><p>Greenplum是基于PostgreSQL的一个完善的数据库，在功能和语法上都要比Hadoop上的SQL引擎Hive好用很多，对于普通用户来说更加容易上手。</p>
</li>
<li><p>Greenplum有着完善的工具，相比Hive，整个体系都比较完善，不需要像Hive一样花太多的时间和精力进行改造，非常适合作为一些大型的数据仓库解决方案。</p>
</li>
<li><p>Greenplum能够方便地与Hadoop进行结合，可直接把数据写在Hadoop上，还可以直接在数据库上写MapReduce任务，并且配置简单。</p>
</li>
</ul>

        
    </section>
</article>


    <article class="article" itemscope itemprop="blogPost">
    
    <header class="article-header">
        
        <h1 itemprop="name">
            <a href="/2019/01/29/世界以痛吻我，我却报之以歌/">世界以痛吻我 我却报之以歌</a>
        </h1>
        
        <div class="article-meta clearfix">
            <a class="article-date" href="https://wxzhongwang.github.io/page/4/index.html">
    
    <i class="icon-calendar"></i>
    
    <time datetime="2019-01-29T09:10:10.000Z" itemprop="datePublished">2019-01-29</time>
</a>

            
<div class="article-tag-list">
    <i class="icon-tag"></i>
    <a class="article-tag-link" href="/tags/个人/">个人</a>
</div>


        </div>
    </header>
    
    <section class="article-body markdown-body">
        
        <p>今年发生不好的事，一切都显得不那么美好，就很多事情都不按大家的预想在发展。就一起都感觉不顺利，2018已经不够友好了，还记得刚刚过去的23岁生日，记得自己的愿望是希望，真挚希望所有的亲朋好友能够健康，健康就够了，钱多钱少不重要，就是健康就够了。。。</p>
<p>但是偏偏还是发生了。</p>
<h1 id="世界以痛吻我-我却报之以歌"><a href="#世界以痛吻我-我却报之以歌" class="headerlink" title="世界以痛吻我 我却报之以歌"></a>世界以痛吻我 我却报之以歌</h1><p>亲人已仙游，未呈儿孙福，幽魂于千里，如何度思量。</p>
<p>2018年06月14日早9：00点，在杭州，还在床上的我猛的收到了家人群的消息，早已患糖尿病多年的舅舅病逝。尽管心里有多不愿意接受，但是心里也算是做好了准备。在五一回家时间便已经被告知舅舅身体日渐消瘦，骨瘦如柴。我还趁着工作之余，抽空去看望了。当看到那一瞬间，我感觉我整个人就不好了，眼泪一下就出来了，整个人像楞住了一般，久久说不出话，手也不知道往哪里放。当舅舅看到我，一把把我拽住，死死捏着，这一幕到现在我也忘不了…</p>
<p>又是在杭州，2019年01月29日早8: 00点，同样的戏码，姨夫病逝，癌症晚期，距离收到通知，也就短短三个多月时间，大概一百多天，原本一个看上去健健康康的人，就突然离开，就像上帝给你的人生突然上了锁，然后把钥匙给扔掉了的感觉…</p>
<p>醒来又是一天，开始干活，累…</p>

        
    </section>
</article>


    <article class="article" itemscope itemprop="blogPost">
    
    <header class="article-header">
        
        <h1 itemprop="name">
            <a href="/2019/01/11/Hadoop Hive Hbase 简单区别及应用场景/">Hadoop Hive Hbase 简单区别及应用场景</a>
        </h1>
        
        <div class="article-meta clearfix">
            <a class="article-date" href="https://wxzhongwang.github.io/page/4/index.html">
    
    <i class="icon-calendar"></i>
    
    <time datetime="2019-01-11T02:10:00.000Z" itemprop="datePublished">2019-01-11</time>
</a>

            
<div class="article-tag-list">
    <i class="icon-tag"></i>
    <a class="article-tag-link" href="/tags/Hadoop/">Hadoop</a>
</div>


        </div>
    </header>
    
    <section class="article-body markdown-body">
        
        <h1 id="Hadoop-Hive-Hbase-简单区别及应用场景"><a href="#Hadoop-Hive-Hbase-简单区别及应用场景" class="headerlink" title="Hadoop Hive Hbase 简单区别及应用场景"></a>Hadoop Hive Hbase 简单区别及应用场景</h1><h2 id="Hadoop"><a href="#Hadoop" class="headerlink" title="Hadoop"></a>Hadoop</h2><p>它是一个分布式计算+分布式文件系统，前者其实就是MapReduce，后者是HDFS。后者可以独立运行，前者可以选择性使用，也可以不使用。</p>
<h2 id="Hive"><a href="#Hive" class="headerlink" title="Hive"></a>Hive</h2><p>通俗的说是一个数据仓库，仓库中的数据是被HDFS管理的数据文件，它支持类似sql语句的功能，<br>你可以通过该语句完成分布式环境下的计算功能，Hive会把语句转换成MapReduce，然后交给Hadoop执行。<br>这里的计算，仅限于查找和分析，而不是更新、增加和删除。它的优势是对历史数据进行处理，<br>用时下流行的说法是离线计算，因为它的底层是MapReduce，MapReduce在实时计算上性能很差。<br>它的做法是把数据文件加载进来作为一个Hive表（或者外部表），让你觉得你的sql操作的是传统的表。</p>
<h2 id="HBase"><a href="#HBase" class="headerlink" title="HBase"></a>HBase</h2><p>通俗的说，HBase的作用类似于数据库，传统数据库管理的是集中的本地数据文件，<br>而HBase基于Hdfs实现对分布式数据文件的管理，比如增删改查。也就是说，HBase只是利用Hadoop的Hdfs帮助其管理数据的持久化文件（HFile），它跟MapReduce没任何关系。HBase的优势在于实时计算，所有实时数据都直接存入Hbase中，客户端通过API直接访问Hbase，实现实时计算。由于它使用的是nosql，或者说是列式结构，从而提高了查找性能，使其能运用于大数据场景，这是它跟MapReduce的区别。</p>
<h2 id="总结："><a href="#总结：" class="headerlink" title="总结："></a>总结：</h2><ol>
<li>Hadoop是Hive和HBase的基础，Hive依赖Hadoop</li>
<li>HBase仅依赖Hadoop的Hdfs模块。</li>
<li>Hive适用于离线数据的分析，操作的是通用格式的（如通用的日志文件）、被Hadoop管理的数据文件，它支持类sql，<br>比编写MapReduce的java代码来的更加方便，它的定位是数据仓库，存储和分析历史数据</li>
<li>Hbase适用于实时计算，采用列式结构的nosql，操作的是自己生成的特殊格式的HFile、被hadoop管理的数据文件，<br>它的定位是数据库，或者叫DBMS</li>
</ol>
<blockquote>
<p>最后补充一下：Hive可以直接操作Hdfs中的文件作为它的表的数据，也可以使HBase数据库作为它的表</p>
</blockquote>

        
    </section>
</article>


    <article class="article" itemscope itemprop="blogPost">
    
    <header class="article-header">
        
        <h1 itemprop="name">
            <a href="/2019/01/08/大数据相关技术（Hadoop体系）/">Hadoop技术体系</a>
        </h1>
        
        <div class="article-meta clearfix">
            <a class="article-date" href="https://wxzhongwang.github.io/page/4/index.html">
    
    <i class="icon-calendar"></i>
    
    <time datetime="2019-01-08T06:18:02.000Z" itemprop="datePublished">2019-01-08</time>
</a>

            
<div class="article-tag-list">
    <i class="icon-tag"></i>
    <a class="article-tag-link" href="/tags/Hadoop/">Hadoop</a>
</div>


        </div>
    </header>
    
    <section class="article-body markdown-body">
        
        <p>Hadoop 里面包括几个组件<strong>HDFS</strong>、<strong>MapReduce</strong>、<strong>YARN</strong>和<strong>ZooKeeper</strong>等一系列技术，HDFS是存储数据的地方就像我们电脑的硬盘一样文件都存储在这个上面，MapReduce是对数据进行处理计算的，YARN是体现Hadoop平台概念的重要组件，有了它大数据生态体系的其它软件就能在hadoop上运行了，这样能更好的利用HDFS大存储的优势和节省更多的资源比如我们就不用再单独建一个spark的集群了，让它直接跑在现有的hadoop yarn上面就可以了。ZooKeeper本身是一个非常牢靠的记事本，用于记录一些概要信息。Hadoop依靠这个记事本来记录当前哪些节点正在用，哪些已掉线，哪些是备用等，以此来管理机群。</p>
<h1 id="Hadoop技术体系"><a href="#Hadoop技术体系" class="headerlink" title="Hadoop技术体系"></a>Hadoop技术体系</h1><h2 id="Hadoop"><a href="#Hadoop" class="headerlink" title="Hadoop"></a>Hadoop</h2><p>Hadoop 里面包括几个组件<strong>HDFS</strong>、<strong>MapReduce</strong>、<strong>YARN</strong>和<strong>ZooKeeper</strong>等一系列技术，HDFS是存储数据的地方就像我们电脑的硬盘一样文件都存储在这个上面，MapReduce是对数据进行处理计算的，YARN是体现Hadoop平台概念的重要组件，有了它大数据生态体系的其它软件就能在hadoop上运行了，这样能更好的利用HDFS大存储的优势和节省更多的资源比如我们就不用再单独建一个spark的集群了，让它直接跑在现有的hadoop yarn上面就可以了。ZooKeeper本身是一个非常牢靠的记事本，用于记录一些概要信息。Hadoop依靠这个记事本来记录当前哪些节点正在用，哪些已掉线，哪些是备用等，以此来管理机群。</p>
<h2 id="HDFS"><a href="#HDFS" class="headerlink" title="HDFS"></a>HDFS</h2><p>Hadoop Distributed File System，Hadoop 分布式文件系统<br>高度容错性的系统，适合部署在廉价的机器上，HDFS能提供高吞吐量的数据访问，适合那些有着超大数据集（large data set）的应用程序。</p>
<h2 id="MapReduce"><a href="#MapReduce" class="headerlink" title="MapReduce"></a>MapReduce</h2><p>Mapreduce是一个计算框架，一个处理分布式海量数据的软件框架及计算集群。</p>
<p>Map （映射） Reduce (简化)<br>举个例子：假设你的手机通话信息保存在一个HDFS的文件callList.txt中，你想找到你与同事A的所有通话记录并排序。因为HDFS会把callLst.txt分成几块分别存，比如说5块，那么对应的Map过程就是找到这5块所在的5个节点，让它们分别找自己存的那块中关于同事A的通话记录，对应的Reduce过程就是把5个节点过滤后的通话记录合并在一块并按时间排序。MapReduce的计算模型通常把HDFS作为数据来源，很少会用到其它数据来源比如HBase。</p>
<h2 id="Hbase"><a href="#Hbase" class="headerlink" title="Hbase"></a>Hbase</h2><p>这是Hadoop生态体系中的NOSQL数据库，他的数据是按照key和value的形式存储的并且key是唯一的，所以它能用来做数据的排重，它与MYSQL相比能存储的数据量大很多。所以他常被用于大数据处理完成之后的存储目的地。</p>
<blockquote>
<p>HDFS和HBase是依靠外存（即硬盘）的分布式文件存储实现和分布式表存储实现。HDFS是一个分布式的“云存储”文件系统，它会把一个文件分块并分别保存，取用时分别再取出、合并。重要的是，这些分块通常会在3个节点（即集群内的服务器）上各有1个备份，因此即使出现少数节点的失效（如硬盘损坏、掉电等），文件也不会失效。如果说HDFS是文件级别的存储，那HBase则是表级别的存储。HBase是表模型，但比SQL数据库的表要简单的多，没有连接、聚集等功能。HBase的表是物理存储到HDFS的，比如把一个表分成4个HDFS文件并存储。由于HDFS级会做备份，所以HBase级不再备份。MapReduce则是一个计算模型，而不是存储模型；MapReduce通常与HDFS紧密配合。</p>
</blockquote>
<h2 id="Hive"><a href="#Hive" class="headerlink" title="Hive"></a>Hive</h2><p>Hive 是一种底层封装了Hadoop 的数据仓库处理工具，使用类SQL的HiveQL语言实现数据查询，所有Hive 的数据都存储在Hadoop 兼容的文件系统（如HDFS）中。Hive在加载数据过程中不会对数据进行任何的修改，只是将数据移动到HDFS中Hive设定的目录下，++因此，Hive不支持对数据的改写和添加，所有的数据都是在加载的时候确定的++。对于会SQL语法的来说就是神器，它能让你处理大数据变的很简单，不会再费劲的编写MapReduce程序。</p>
<h2 id="Spark"><a href="#Spark" class="headerlink" title="Spark"></a>Spark</h2><p>它是用来弥补基于MapReduce处理数据速度上的缺点，它的特点是把数据装载到内存中计算而不是去读慢的要死进化还特别慢的硬盘。特别适合做迭代运算，所以算法流们特别稀饭它。它是用scala编写的。Java语言或者Scala都可以操作它，因为它们都是用JVM的。</p>
<h1 id="其他相关技术"><a href="#其他相关技术" class="headerlink" title="其他相关技术"></a>其他相关技术</h1><h2 id="Sqoop"><a href="#Sqoop" class="headerlink" title="Sqoop"></a>Sqoop</h2><p>这个是用于把Mysql里的数据导入到Hadoop里的。当然你也可以不用这个，直接把Mysql数据表导出成文件再放到HDFS上也是一样的，当然生产环境中使用要注意Mysql的压力。</p>
<h2 id="Flume"><a href="#Flume" class="headerlink" title="Flume"></a>Flume</h2><p> apache Flume 是一个从可以收集例如日志，事件等数据资源，并将这些数量庞大的数据从各项数据资源中集中起来存储的工具/服务，或者数集中机制。flume具有高可用，分布式，配置工具，其设计的原理也是基于数据流，如日志数据从各种网站服务器上汇集起来存储到HDFS，HBase等集中存储器中。</p>
<h3 id="一般实时系统，所选用组件如下"><a href="#一般实时系统，所选用组件如下" class="headerlink" title="一般实时系统，所选用组件如下"></a>一般实时系统，所选用组件如下</h3><ul>
<li>数据采集 ：负责从各节点上实时采集数据，选用Flume来实现  </li>
<li>数据接入 ：由于采集数据的速度和数据处理的速度不一定同步，因此添加一个消息中间件来作为缓冲，选用apache的kafka  </li>
<li>流式计算 ：对采集到的数据进行实时分析，选用apache的storm  </li>
<li>数据输出 ：对分析后的结果持久化，暂定用mysql，另一方面是模块化之后，假如当Storm挂掉了之后，数据采集和数据接入还是继续在跑着，数据不会丢失，storm起来之后可以继续进行流式计算； </li>
</ul>
<h2 id="Kafka"><a href="#Kafka" class="headerlink" title="Kafka"></a>Kafka</h2><p>Kafka的整体架构非常简单，是显式分布式架构，producer、broker（kafka）和consumer都可以有多个。Producer，consumer实现Kafka注册的接口，数据从producer发送到broker，broker承担一个中间缓存和分发的作用。broker分发注册到系统中的consumer。broker的作用类似于缓存，即活跃的数据和离线处理系统之间的缓存。客户端和服务器端的通信，是基于简单，高性能，且与编程语言无关的TCP协议。</p>
<p>Kafka是一种分布式的、基于发布/订阅的消息系统。在流式计算中，Kafka一般用来缓存数据，Storm通过消费Kafka的数据进行计算（KAFKA+STORM+REDIS）。</p>
<p>特点：</p>
<ul>
<li>消息持久化：通过O(1)的磁盘数据结构提供数据的持久化</li>
<li>高吞吐量：每秒百万级的消息读写</li>
<li>分布式：扩展能力强</li>
<li>多客户端支持：java、php、python、c++ ……</li>
<li>实时性：生产者生产的message立即被消费者可见</li>
<li>Kafka是一个分布式消息队列：生产者、消费者的功能。它提供了类似于JMS的特性，但是在设计实   现上完全不同，此外它并不是JMS规范的实现。</li>
<li>Kafka对消息保存时根据Topic进行归类，发送消息者称为Producer,消息接受者称为Consumer</li>
<li>无论是kafka集群，还是producer和consumer都依赖于zookeeper集群保存一些meta信息，来保证系统可用性</li>
</ul>

        
    </section>
</article>


    <article class="article" itemscope itemprop="blogPost">
    
    <header class="article-header">
        
        <h1 itemprop="name">
            <a href="/2019/01/08/大数据/">大数据</a>
        </h1>
        
        <div class="article-meta clearfix">
            <a class="article-date" href="https://wxzhongwang.github.io/page/4/index.html">
    
    <i class="icon-calendar"></i>
    
    <time datetime="2019-01-08T06:18:02.000Z" itemprop="datePublished">2019-01-08</time>
</a>

            
<div class="article-tag-list">
    <i class="icon-tag"></i>
    <a class="article-tag-link" href="/tags/大数据/">大数据</a>
</div>


        </div>
    </header>
    
    <section class="article-body markdown-body">
        
        <h1 id="大数据生命周期"><a href="#大数据生命周期" class="headerlink" title="大数据生命周期"></a>大数据生命周期</h1><ul>
<li>基础设施层，涵盖计算资源、内存与存储和网络互联，具体表现为计算节点、集群、机柜和数据中心。</li>
<li>数据存储和管理层，包括文件系统、数据库和类似YARN的资源管理系统。</li>
<li>计算处理层，如hadoop、MapReduce和Spark</li>
<li>在此之上的各种不同计算范式，如批处理、流处理和图计算等，包括衍生出编程模型的计算模型，如BSP、GAS等</li>
</ul>
<blockquote>
<p>数据分析和可视化基于计算处理层。分析包括简单的查询分析、流分析以及更复杂的分析(如机器学习、图计算等)。查询分析多基于表结构和关系函数，流分析基于数据、事件流以及简单的统计分析，而复杂分析则基于更复杂的数据结构与方法，如图、矩阵、迭代计算和线性代数。一般意义的可视化是对分析结果的展示。但是通过交互式可视化，还可以探索性地提问，使分析获得新的线索，形成迭代的分析和可视化。基于大规模数据的实时交互可视化分析以及在这个过程中引入自动化的因素是目前研究的热点。</p>
</blockquote>
<h1 id="大数据技术生态"><a href="#大数据技术生态" class="headerlink" title="大数据技术生态"></a>大数据技术生态</h1><p>大数据的基本处理流程与传统数据处理流程并无太大差异，主要区别在于：由于大数据要处理大量、非结构化的数据，所以在各处理环节中都可以采用并行处理。目前，Hadoop、MapReduce和Spark等分布式处理方式已经成为大数据处理各环节的通用处理方法。</p>
<h1 id="大数据采集与预处理"><a href="#大数据采集与预处理" class="headerlink" title="大数据采集与预处理"></a>大数据采集与预处理</h1><ul>
<li>存储层</li>
<li>预处理层</li>
<li>采集层</li>
</ul>
<p>在大数据的生命周期中，数据采集处于第一个环节。根据MapReduce产生数据的应用系统分类，大数据的采集主要有4种来源：管理信息系统、Web信息系统、物理信息系统、科学实验系统。对于不同的数据集，可能存在不同的结构和模式，如文件、XML树、关系表等，表现为数据的异构性。对多个异构的数据集，需要做进一步集成处理或整合处理，将来自不同数据集的数据收集、整理、清洗、转换后，生成到一个新的数据集，为后续查询和分析处理提供统一的数据视图。针对管理信息系统中异构数据库集成技术、Web信息系统中的实体识别技术和DeepWeb集成技术、传感器网络数据融合技术已经有很多研究工作，取得了较大的进展，已经推出了多种数据清洗和质量控制工具。</p>
<h1 id="大数据的存储和管理"><a href="#大数据的存储和管理" class="headerlink" title="大数据的存储和管理"></a>大数据的存储和管理</h1><p>按数据类型的不同，大数据的存储和管理采用不同的技术路线，大致可以分为3类。</p>
<h2 id="第1类"><a href="#第1类" class="headerlink" title="第1类"></a>第1类</h2><p>主要面对的是大规模的结构化数据。针对这类大数据，通常采用新型数据库集群。它们通过列存储或行列混合存储以及粗粒度索引等技术，结合MPP(MassiveParallelProcessing)架构高效的分布式计算模式，实现对PB量级数据的存储和管理。这类集群具有高性能和高扩展性特点，在企业分析类应用领域已获得广泛应用;</p>
<h2 id="第2类"><a href="#第2类" class="headerlink" title="第2类"></a>第2类</h2><p>主要面对的是半结构化和非结构化数据。应对这类应用场景，基于Hadoop开源体系的系统平台更为擅长。它们通过对Hadoop生态体系的技术扩展和封装，实现对半结构化和非结构化数据的存储和管理;</p>
<h2 id="第3类"><a href="#第3类" class="headerlink" title="第3类"></a>第3类</h2><p>面对的是结构化和非结构化混合的大数据，因此采用MPP并行数据库集群与Hadoop集群的混合来实现对百PB量级、EB量级数据的存储和管理。一方面，用MPP来管理计算高质量的结构化数据，提供强大的SQL和OLTP型服务;另一方面，用Hadoop实现对半结构化和非结构化数据的处理，以支持诸如内容检索、深度挖掘与综合分析等新型应用。这类混合模式将是大数据存储和管理未来发展的趋势。</p>

        
    </section>
</article>


    <article class="article" itemscope itemprop="blogPost">
    
    <header class="article-header">
        
        <h1 itemprop="name">
            <a href="/2019/01/08/流处理、批处理、交互式查询/">流处理、批处理、交互式查询</a>
        </h1>
        
        <div class="article-meta clearfix">
            <a class="article-date" href="https://wxzhongwang.github.io/page/4/index.html">
    
    <i class="icon-calendar"></i>
    
    <time datetime="2019-01-08T06:18:02.000Z" itemprop="datePublished">2019-01-08</time>
</a>

            
<div class="article-tag-list">
    <i class="icon-tag"></i>
    <a class="article-tag-link" href="/tags/Hadoop/">Hadoop</a>
</div>


        </div>
    </header>
    
    <section class="article-body markdown-body">
        
        <pre><code>我们将大数据处理按处理时间的跨度要求分为以下几类

基于实时数据流的处理，通常的时间跨度在数百毫秒到数秒之间

基于历史数据的交互式查询，通常时间跨度在数十秒到数分钟之间

复杂的批量数据处理，通常的时间跨度在几分钟到数小时之间
</code></pre>
        
    </section>
</article>


    <article class="article" itemscope itemprop="blogPost">
    
    <header class="article-header">
        
        <h1 itemprop="name">
            <a href="/2019/01/08/Hadoop/">Hadoop概念</a>
        </h1>
        
        <div class="article-meta clearfix">
            <a class="article-date" href="https://wxzhongwang.github.io/page/4/index.html">
    
    <i class="icon-calendar"></i>
    
    <time datetime="2019-01-08T06:18:02.000Z" itemprop="datePublished">2019-01-08</time>
</a>

            
<div class="article-tag-list">
    <i class="icon-tag"></i>
    <a class="article-tag-link" href="/tags/Hadoop/">Hadoop</a>
</div>


        </div>
    </header>
    
    <section class="article-body markdown-body">
        
        <p>Hadoop是一个开源的框架，可编写和运行分布式应用处理大规模数据，是专为离线和大规模数据分析而设计的，并不适合那种对几个记录随机读写的在线事务处理模式。</p>
<h1 id="Hadoop"><a href="#Hadoop" class="headerlink" title="Hadoop"></a>Hadoop</h1><h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h2><ul>
<li>Hadoop是一个开源的框架，可编写和运行分布式应用处理大规模数据，是专为离线和大规模数据分析而设计的，并不适合那种对几个记录随机读写的在线事务处理模式。 ==不是为了大数据而大数据==</li>
<li>Hadoop 是以一种可靠、高效、可伸缩的方式进行处理的。Hadoop 是可靠的，因为它假设计算元素和存储会失败，因此它维护多个工作数据副本，确保能够针对失败的节点重新分布处理。Hadoop 是高效的，因为它以并行的方式工作，通过并行处理加快处理速度。Hadoop 还是可伸缩的，能够处理 PB 级数据。</li>
</ul>
<h2 id="核心"><a href="#核心" class="headerlink" title="核心"></a>核心</h2><p>Hadoop的核心就是==HDFS==和==MapReduce===，Hadoop旗下有很多经典子项目，比如HBase、Hive等，这些都是基于HDFS和MapReduce发展出来的。要想了解Hadoop，就必须知道HDFS和MapReduce是什么。</p>
<h3 id="HDFS"><a href="#HDFS" class="headerlink" title="HDFS"></a>HDFS</h3><p>Hadoop Distributed File System，Hadoop 分布式文件系统<br>高度容错性的系统，适合部署在廉价的机器上，HDFS能提供高吞吐量的数据访问，<br>适合那些有着超大数据集（large data set）的应用程序。</p>
<h3 id="MapReduce"><a href="#MapReduce" class="headerlink" title="MapReduce"></a>MapReduce</h3><p>Mapreduce是一个计算框架，一个处理分布式海量数据的软件框架及计算集群。</p>
<h2 id="用处"><a href="#用处" class="headerlink" title="用处"></a>用处</h2><ul>
<li>搜索引擎 - 设计Hadoop的初衷，为了针对大规模的网页快速建立索引）</li>
<li>大数据存储 - 利用Hadoop的分布式存储能力，例如数据备份、数据仓库等。</li>
<li>大数据处理 - 利用Hadoop的分布式处理能力，例如数据挖掘、数据分析等。</li>
<li>科学研究 - Hadoop是一种分布式的开源框架，对于分布式计算有很大程度地参考价值。</li>
</ul>
<h2 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h2><h3 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h3><p>==高可靠性==<br>Hadoop按位存储和处理数据的能力值得信赖。</p>
<p>==高扩展性==<br>Hadoop是在可用的计算机集簇间分配数据并完成计算任务的，这些集簇可以方便地扩展到数以千计的节点中。</p>
<p>==高效性==<br>Hadoop能够在节点之间动态地移动数据，并保证各个节点的动态平衡，因此处理速度非常快。</p>
<p>==高容错性==<br>Hadoop能够自动保存数据的多个副本，并且能够自动将失败的任务重新分配。</p>
<p>==低成本==<br>与一体机、商用数据仓库以及QlikView、Yonghong Z-Suite等数据集市相比，hadoop是开源的，<br>项目的软件成本因此会大大降低。</p>
<blockquote>
<p>Hadoop设计对硬件需求比较低，只须运行在低廉的商用硬件集群上，而无需昂贵的高可用性机器上。<br>廉价的商用机也就意味着大型集群中出现节点故障情况的概率非常高。这就要求设计HDFS时要充分考虑数据的可靠性，<br>安全性及高可用性。</p>
</blockquote>
<h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h3><p>==不适合低延迟数据访问==</p>
<blockquote>
<p>如果要处理一些用户要求时间比较短的低延迟应用请求，则HDFS不适合。HDFS是为了处理大型数据集分析任务的，主要是为达到高的数据吞吐量而设计的，这就可能要求以高延迟作为代价。</p>
</blockquote>
<blockquote>
<p>改进策略：对于那些有低延时要求的应用程序，HBase是一个更好的选择。通过上层数据管理项目来尽可能地弥补这个不足。在性能上有了很大的提升，它的口号就是goes real time。使用缓存或多master设计可以降低client的数据请求压力，以减少延时。还有就是对HDFS系统内部的修改，这就得权衡大吞吐量与低延时了，HDFS不是万能的银弹。</p>
</blockquote>
<p>==无法高效存储大量小文件==</p>
<blockquote>
<p>因为Namenode把文件系统的元数据放置在内存中，所以文件系统所能容纳的文件数目是由Namenode的内存大小来决定。一般来说，每一个文件、文件夹和Block需要占据150字节左右的空间，所以，如果你有100万个文件，每一个占据一个Block，你就至少需要300MB内存。当前来说，数百万的文件还是可行的，当扩展到数十亿时，对于当前的硬件水平来说就没法实现了。还有一个问题就是，因为Maptask的数量是由splits来决定的，所以用MR处理大量的小文件时，就会产生过多的Maptask，线程管理开销将会增加作业时间。举个例子，处理10000M的文件，若每个split为1M，那就会有10000个Maptasks，会有很大的线程开销；若每个split为100M，则只有100个Maptasks，每个Maptask将会有更多的事情做，而线程的管理开销将减小很多。</p>
</blockquote>
<p>==不支持多用户写入及任意修改文件==  </p>
<blockquote>
<p>在HDFS的一个文件中只有一个写入者，而且写操作只能在文件末尾完成，即只能执行追加操作。目前HDFS还不支持多个用户对同一文件的写操作，以及在文件任意位置进行修改。</p>
</blockquote>

        
    </section>
</article>




<nav class="page-nav">
    <a class="extend prev" rel="prev" href="/page/3/">&laquo; 上一页</a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><span class="page-number current">4</span><a class="page-number" href="/page/5/">5</a><a class="page-number" href="/page/6/">6</a><span class="space">&hellip;</span><a class="page-number" href="/page/23/">23</a><a class="extend next" rel="next" href="/page/5/">下一页 &raquo;</a>
</nav>


</div>
        <footer class="footer">
    Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>, Theme by <a href="https://github.com/sanonz/hexo-theme-concise" target="_blank">Concise</a>

    
    <script>
        var _hmt = _hmt || [];
        (function () {
            var hm = document.createElement("script");
            hm.src = "https://hm.baidu.com/hm.js?e4027971a230b210f4671f485b33846a";
            var s = document.getElementsByTagName("script")[0];
            s.parentNode.insertBefore(hm, s);
        })();
    </script>
    
</footer>

    </main>

    <script type="text/javascript" src="https://cdn.bootcss.com/jquery/1.9.0/jquery.min.js"></script>
    <script type="text/javascript">
    $(function() {
        var nodes = {
            nav: $('#nav'),
            aside: $('#aside'),
            asideInner: $('#aside-inner'),
            navInner: $('#nav-inner')
        };

        var doing = false;
        nodes.asideInner.on('webkitAnimationEnd mozAnimationEnd oAnimationEnd oanimationend animationend', function() {
            if (nodes.aside.hasClass('mobile-open')) {
                nodes.aside.removeClass('mobile-open');
            } else {
                nodes.aside.removeClass('mobile-close panel-show');
            }
            doing = false;
        });
        $('#open-panel, #aside-mask').on('click', function() {
            if (doing) {
                return;
            }
            
            if (nodes.aside.hasClass('panel-show')) {
                nodes.aside.addClass('mobile-close');
            } else {
                nodes.aside.addClass('mobile-open panel-show');
            }
        });
        $('#open-menus').on('click', function() {
            nodes.navInner.slideToggle();
        });

        if (window.innerWidth <= 960) {
            setTimeout(function() {
                nodes.navInner.slideUp();
            }, 3000);
        }
    });
    </script>
    

</body>
</html>
